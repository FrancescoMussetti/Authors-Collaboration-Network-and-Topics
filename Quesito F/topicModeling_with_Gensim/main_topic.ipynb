{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e8f8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim import models\n",
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb543be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import LDA\n",
    "from generic_functions import process_words, visualize_topics, sent_to_words, format_topics_sentences, \\\n",
    "    show_topic_clusters, show_word_cloud, plot_topic_evolution\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3c21d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b7207",
   "metadata": {
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Setting general parameters:\n",
    "    n_topics = 6\n",
    "    n_words = 10\n",
    "    start = 4\n",
    "    limit = 11\n",
    "    step = 1\n",
    "\n",
    "    # Import del DataSet e formattazione:\n",
    "    dataset = pd.read_excel(\"./../../Dataset/Dataset_Corona_1949_2023_FINALE.xlsx\")\n",
    "    print(dataset.isna().sum())\n",
    "    dataset = dataset.dropna()\n",
    "    print(dataset.isna().sum())\n",
    "\n",
    "    # Prepare data for LDA:\n",
    "    dataset_Only_Abstract = dataset[\"Abstract\"]\n",
    "    data_words = list(sent_to_words(dataset_Only_Abstract))\n",
    "\n",
    "    # Building bigram and trigram models:\n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=150)  # higher threshold fewer phrases\n",
    "    trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    data_ready = process_words(\n",
    "        data_words,\n",
    "        bigram_mod=bigram_mod,\n",
    "        trigram_mod=trigram_mod\n",
    "    )\n",
    "\n",
    "    # Create Dictionary:\n",
    "    id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "    # Create Corpus (Term Document Frequency):\n",
    "    corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "    # LDA Model:\n",
    "    print(f\"\\n\\n ########## LATENT DIRICHLET ALLOCATION:    ############\")\n",
    "    print(f\"\\n^^^^ Contributo delle {n_words} parole pi√π importanti per {n_topics} Topics: ^^^^\")\n",
    "    lda_model = LDA.create_lda_model(corpus, id2word, n_topics, n_words)\n",
    "    # Format topics and sentences:\n",
    "    df_topic_sents_keywords = format_topics_sentences(model=lda_model, corpus=corpus, texts=data_ready)\n",
    "    df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "    df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "    # Add PMID column:\n",
    "    pmid_list = dataset['PMID'].tolist()\n",
    "    df_dominant_topic['PMID'] = pmid_list\n",
    "\n",
    "    ################ CREATE & EXPORT DATASET WITH TOPICS #################################################\n",
    "    # Merge the two dataframes based on PMID:\n",
    "    df_new = pd.merge(dataset, df_dominant_topic[['PMID', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords']],\n",
    "                      on='PMID', how='inner')\n",
    "    # Export the DataFrame containing topic information for each document to an Excel file:\n",
    "    df_new.to_excel('Dataset_Corona_1949_2023_TOPIC_new.xlsx', index=False, sheet_name='Sheet1', startrow=0, startcol=0)\n",
    "\n",
    "    ##===### Visualize WordCloud for each Topics in LDA Model:\n",
    "    print(\"\\nVisualize WordCloud for each Topics in LDA Model... (Vedi grafico)\")\n",
    "    show_word_cloud(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63704760",
   "metadata": {
    "lines_to_next_cell": 2,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "############ ^^^^^^^^^ Visualize HTML reports of topics and topic clusters: ^^^^^^^^^^^^^^^^\n",
    "    #TOPIC CLUSTERS\n",
    "    print(f\"\\n^^^^ Informazioni relative alla generazione dei Cluster: ^^^^\")\n",
    "    show_topic_clusters(lda_model, corpus, n_topics=n_topics)\n",
    "    ### TOPICS TOP-30 MOST SALIENT TERMS:\n",
    "    visualize_topics(lda_model, corpus)\n",
    "\n",
    "\n",
    "    # Visualize the Evolution of Topics during the Years:\n",
    "    plot_topic_evolution(lda_model, corpus, dataset)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}